# ğŸ›°ï¸ JobSentinel  
**Self-hosted job intelligence system â€” private, automated, and free to run locally.**

JobSentinel scrapes multiple job sites, scores each role against your preferences, and alerts you only to high-value matches â€” automatically.  
Itâ€™s built for *anyone* whoâ€™s tired of endless scrolling, fake postings, and recruiter spam.

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Run%20with-Docker-blue.svg)](https://www.docker.com/)
[![Slack Alerts](https://img.shields.io/badge/Alerts-Slack-4A154B.svg?logo=slack)](https://slack.com/)
[![Privacy](https://img.shields.io/badge/Privacy-Local%20First-black.svg)](#)
[![Status](https://img.shields.io/badge/Status-Active-success.svg)](#)

---

ğŸ”’ **Why JobSentinel?**
Because job boards are full of noise, paywalls, and fake listings.  
JobSentinel gives you the power to automate your search, stay private, and never waste time chasing ghosts again.  
Free if you run it locally. Always yours. Always private.

---

ğŸ§  **Coming Soon**
- More source integrations (Lever, Workable, ZipRecruiter)
- Ghost-job detection scoring
- Optional notifications via Discord, Telegram, or email
- Web dashboard and quick setup UI

---
# Job Search Automation

âš ï¸ **Alpha software.** It works, but there are bugs. I use it daily. Test locally first.

## What It Does

I built this because hunting jobs manually sucks. This scrapes multiple sites, scores each role against your skills, and alerts you to matches worth checking.

**The Process:**

- Scrapes Greenhouse, Lever, JobsWithGPT, Reed, and JobSpy multiâ€‘site aggregation (~500k+ jobs)
- Scores each job against your preferences
- Sends highâ€‘scoring matches to Slack
- Stores everything locally (your data stays yours)

**Status:** Local mode works today. Cloud deployment typically costs **$5â€“15/month**.

---

## Quick Start

### Windows
Use the guided installer:

```powershell
python scripts\setup\windows_local_installer.py
```

### macOS / Linux

```bash
git clone https://github.com/cboyd0319/JobSentinel
cd JobSentinel

python3 -m venv .venv
source .venv/bin/activate
python -m pip install -r requirements.txt
python -m pip install -e .[dev]

# Copy and edit your user preferences
cp config/user_prefs.example.json config/user_prefs.json

# Run web UI (new CLI)
jsa web --port 5000
```

---

## Features

- **Multi-site scraping** â€“ Greenhouse, Lever, JobsWithGPT, Reed, JobSpy aggregation
- **Smart scoring** â€“ Keyword matching, salary filtering, company blacklists
- **Slack alerts** â€“ Highâ€‘scoring matches with score breakdowns
- **Localâ€‘first** â€“ Your data stays on your machine
- **Cloud option** â€“ Auto-runs every 2 hours (approx. **$5â€“15/month**)

---

## System Requirements

| Platform                         | Status        | Notes                         |
|----------------------------------|---------------|-------------------------------|
| Windows 10/11 + PowerShell 5.1+ | âœ… Supported  | Guided installer available    |
| macOS 13+                        | âš ï¸ Manual     | Python 3.11+ required         |
| Ubuntu/Linux                     | âš ï¸ Manual     | Python 3.11+ required         |

---

## Configuration

Edit `config/user_prefs.json` and set your preferences. Example:

```json
{
  "keywords": ["python", "backend", "api"],
  "locations": ["San Francisco, CA", "Remote"],
  "salary_min": 120000,
  "blacklisted_companies": ["Meta"],
  "resume": {
    "enabled": true,
    "file_path": "/path/to/resume.pdf"
  },
  "job_sources": {
    "jobswithgpt": { "enabled": true },
    "reed": { "enabled": true, "api_key": "your_reed_key" }
  },
  "slack": {
    "webhook_url": "your_slack_webhook",
    "channel": "#job-alerts"
  }
}
```

**Get API keys:**  
- Reed: <https://reed.co.uk/developers>  
- Slack: Workspace settings â†’ **Apps** â†’ **Incoming Webhooks**

---

## Commands

### New CLI (modularized core)

After `pip install -e .`, use the typed CLI:

```bash
jsa web --port 5000           # run local web UI
jsa config-validate --path config/user_prefs.json
jsa health                    # print quick health summary
```


# ğŸ›°ï¸ JobSentinel  
**Self-hosted job intelligence system â€” private, automated, and free to run locally.**

JobSentinel scrapes multiple job sites, scores each role against your preferences, and alerts you only to high-value matches â€” automatically.  
Itâ€™s built for *anyone* whoâ€™s tired of endless scrolling, fake postings, and recruiter spam.

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Run%20with-Docker-blue.svg)](https://www.docker.com/)
[![Slack Alerts](https://img.shields.io/badge/Alerts-Slack-4A154B.svg?logo=slack)](https://slack.com/)
[![Privacy](https://img.shields.io/badge/Privacy-Local%20First-black.svg)](#)
[![Status](https://img.shields.io/badge/Status-Active-success.svg)](#)

---

### ğŸ§© What It Does

I built this because hunting jobs manually sucks.  
This scrapes multiple sites, scores each role against your skills, and alerts you to matches worth checking.

**The Process:**
- Scrapes Indeed, LinkedIn, and Greenhouse (~500k+ jobs)
- Scores each job against your preferences
- Sends high-scoring matches to Slack
- Stores everything locally (your data stays yours)

**Status:**  
âœ… Local mode works today  
â˜ï¸ Cloud deployment typically costs **$5â€“15/month**

---

### âš™ï¸ Features

- ğŸŒ **Multi-site scraping** â€“ Indeed, LinkedIn, Greenhouse  
- ğŸ§  **Smart scoring** â€“ Keyword matching, salary filtering, company blacklists  
- ğŸ’¬ **Slack alerts** â€“ High-scoring matches with score breakdowns  
- ğŸ’¾ **Local-first** â€“ Your data stays on your machine  
- â˜ï¸ **Cloud option** â€“ Auto-runs every 2 hours (~$5â€“15/month)

---

### ğŸš€ Quick Start

```bash
# Clone the repo
./psqa.ps1 -Mode analyze
cd JobSentinel

# Run locally


# Or deploy to your own private cloud (GCP, AWS, Azure)
# Costs around $5â€“15/month for continuous operation
```

---
# Autoâ€‘fix issues
./psqa.ps1 -Mode fix
```

PowerShell quality is **zeroâ€‘tolerance**â€”fix before commit.

---

## Troubleshooting

- **No jobs found:** Check `data/logs/*.log`
- **Slack not working:** `python scripts/setup/slack/slack_setup.py --test-only`
- **Import errors:** Verify Python **3.11+**, then reinstall `requirements.txt`
- **Permission issues (Windows):** Run PowerShell **as Administrator**

Test a single scraper:

```bash
python sources/jobswithgpt_scraper.py --test
```

Webhook smoke test:

```bash
curl -X POST -H 'Content-type: application/json'   --data '{"text":"Test"}' YOUR_WEBHOOK_URL
```

Rate limiting (example):

```json
{
  "request_delay": 2.0,
  "max_retries": 3
}
```

---

## Architecture

```text
src/
â”œâ”€â”€ agent.py                  # Main orchestrator
â”œâ”€â”€ database.py               # SQLite storage
â”œâ”€â”€ web_ui.py                 # Legacy shim; new web lives in jsa.web
jsa/                         # New typed core package (under src/jsa)
â”œâ”€â”€ web/app.py               # Flask app factory: create_app()
â”œâ”€â”€ web/blueprints/*.py      # Split routes: main, skills, review, slack
â”œâ”€â”€ http/sanitization.py     # Safe URL utilities
â”œâ”€â”€ config.py                # Typed config facade
â””â”€â”€ logging.py               # Structured logging wrapper
sources/
â”œâ”€â”€ jobswithgpt_scraper.py    # JobsWithGPT API integration
â”œâ”€â”€ reed_mcp_scraper.py       # Reed.co.uk API
â”œâ”€â”€ jobspy_mcp_scraper.py     # JobSpy MCP multiâ€‘site aggregation
â”œâ”€â”€ greenhouse_scraper.py     # Greenhouse
â””â”€â”€ lever_scraper.py          # Lever
notify/
â”œâ”€â”€ slack.py                  # Slack notifications
â””â”€â”€ emailer.py                # Email alerts (optional)
```

See also: docs/ARCHITECTURE.md for refactor overview.

---

## Quality Pipeline

Recommended dev workflow (inside a venv):

```bash
make fmt        # format
make lint       # ruff
make type       # mypy (strict on src/jsa)
make test-core  # tests for new core
make cov        # coverage for src/jsa
```

Optional: mutation tests

```bash
make mut  # requires: pip install mutmut
```

Legacy config files in config/ are retained for compatibility, but the root-level pyproject.toml is authoritative for packaging and tooling.

### MegaLinter (CI)

This repo includes a MegaLinter workflow that validates the full codebase with fast, pragmatic linters (Markdown, YAML, JSON, Shell, PowerShell, Dockerfile, secrets) and runs Python linters only on the new typed core and its tests. Reports are uploaded as CI artifacts under â€œmega-linter-reportsâ€.

Local usage is optional; CI runs automatically on PRs and pushes to `main`.

---

## Contributing

1) Setup venv and install dev dependencies (see Quick Start).  
2) Enable pre-commit hooks:

```bash
pre-commit install
pre-commit run --all-files
```

3) Before opening a PR:
- make fmt && make lint && make type && make test-core
- Ensure no secrets are committed; read SECURITY.md
- Keep changes small and focused; add/adjust tests


**Key files:**

- `config/user_prefs.json` â€“ Your settings  
- `logs/agent.log` â€“ Main log file  
- `data/jobs.sqlite` â€“ Job database (SQLite)  
- `psqa.ps1` â€“ PowerShell quality checker

---

## Development

```bash
# PowerShell quality (Windows)
./psqa.ps1

# Python quality (new core)
make fmt && make lint && make type && make test-core

# Security scan (core)
python -m bandit -r src/jsa
```

**Add a new job source:**

1. Create scraper in `sources/`
2. Inherit from `JobScraperBase`
3. Add it to `config/user_prefs.json`
4. Test with `--dry-run`

---

## Security Notes

- API keys live in config filesâ€”**never** commit them
- Local runs use local SQLite by default
- Scrapers respect `robots.txt`
- Builtâ€‘in rate limiting
- No personal data stored beyond job matches

**Cloud security:** Use **separate API keys** for local vs. cloud.

---

## FAQ

**How often should I run this?**  
Daily or every few hours. More frequent runs increase rateâ€‘limit risk.

**What if a site blocks me?**  
Increase delays, use a VPN, or disable that source temporarily.

**Can I customize scoring?**  
Yesâ€”see `matchers/rules.py` for keyword weights and scoring logic.

**Where is my data stored?**  
Locally in `data/jobs.sqlite`. Cloud deployments use separate databases.

**Why not use job boards' APIs?**  
Most donâ€™t have public APIs; available ones are limited or expensive.

---

## License

MIT License.

**Alpha softwareâ€”use at your own risk.** I use it daily, but it has bugs.  
**Questions?** Check `TROUBLESHOOTING.md` or open a GitHub issue.
Health endpoint:

- GET `/healthz` returns `{ ok: bool, stats: { total_jobs, high_score_jobs } }`

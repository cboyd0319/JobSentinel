# Architecture Documentation

**JobSentinel v1.3 System Architecture**

---

## Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Module Breakdown](#module-breakdown)
- [Data Flow](#data-flow)
- [Technology Stack](#technology-stack)
- [Design Principles](#design-principles)
- [Security Architecture](#security-architecture)

---

## Overview

JobSentinel is a **privacy-first, desktop-native job search automation tool** built with Rust and Tauri. The application runs entirely on the user's machine with no cloud dependencies (v1.0), ensuring complete data privacy and control.

### Key Characteristics

- **Desktop-first**: Native Windows/macOS/Linux application
- **Privacy-focused**: All data stored locally, no telemetry
- **Async-first**: Built on Tokio for efficient I/O
- **Type-safe**: Leverages Rust's type system for correctness
- **Modular**: Clean separation between core logic and platform code

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React 19)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Dashboard   â”‚  â”‚    Settings   â”‚  â”‚  Job Browser  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                  â”‚                  â”‚                â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                             â”‚                                   â”‚
â”‚                    Tauri IPC (Commands)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Backend (Rust/Tauri)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚          Commands Layer (Tauri RPC)                 â”‚       â”‚
â”‚  â”‚  - search_jobs      - get_config                    â”‚       â”‚
â”‚  â”‚  - get_recent_jobs  - save_config                   â”‚       â”‚
â”‚  â”‚  - get_statistics   - validate_slack_webhook        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                 â”‚                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚               Core Business Logic                   â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚       â”‚
â”‚  â”‚  â”‚ Schedulerâ”‚  â”‚  Scoring â”‚  â”‚  Notify  â”‚          â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚       â”‚
â”‚  â”‚       â”‚             â”‚             â”‚                 â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”‚       â”‚
â”‚  â”‚  â”‚ Scrapers  â”‚   Database   â”‚  Config  â”‚           â”‚       â”‚
â”‚  â”‚  â”‚-Greenhouseâ”‚   (SQLite)   â”‚  (JSON)  â”‚           â”‚       â”‚
â”‚  â”‚  â”‚-Lever     â”‚              â”‚          â”‚           â”‚       â”‚
â”‚  â”‚  â”‚-JobsGPT   â”‚              â”‚          â”‚           â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                             â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚         Platform-Specific Layer                     â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚       â”‚
â”‚  â”‚  â”‚ Windows  â”‚  â”‚  macOS   â”‚  â”‚  Linux   â”‚          â”‚       â”‚
â”‚  â”‚  â”‚ - Paths  â”‚  â”‚ - Paths  â”‚  â”‚ - Paths  â”‚          â”‚       â”‚
â”‚  â”‚  â”‚ - Tray   â”‚  â”‚ - Tray   â”‚  â”‚ - Tray   â”‚          â”‚       â”‚
â”‚  â”‚  â”‚ - Notify â”‚  â”‚ - Notify â”‚  â”‚ - Notify â”‚          â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Module Breakdown

### 1. Core (`src/core/`)

Platform-agnostic business logic that can run on any OS or in the cloud.

#### `core/config/`
**Purpose**: Configuration management
- Load/save user preferences
- Validate configuration values
- Provide sensible defaults

**Key Types:**
```rust
pub struct Config {
    title_allowlist: Vec<String>,
    salary_floor_usd: i64,
    immediate_alert_threshold: f64,
    alerts: AlertConfig,
    // ...
}
```

**Validation Rules:**
- Salary: 0 â‰¤ value â‰¤ $10M
- Alert threshold: 0.0 â‰¤ value â‰¤ 1.0
- Scraping interval: 1h â‰¤ value â‰¤ 168h
- String lengths enforced
- URL format validation

#### `core/db/`
**Purpose**: SQLite database abstraction
- Job storage and retrieval
- Full-text search (FTS5)
- Statistics aggregation

**Key Operations:**
```rust
upsert_job()        // Insert or update job
get_recent_jobs()   // Get N most recent jobs
get_jobs_by_score() // Filter by score threshold
search_jobs()       // Full-text search
get_statistics()    // Aggregate stats
```

**Schema:**
```sql
CREATE TABLE jobs (
    id INTEGER PRIMARY KEY,
    hash TEXT UNIQUE NOT NULL,
    title TEXT NOT NULL,
    company TEXT NOT NULL,
    score REAL,
    created_at TEXT NOT NULL,
    -- ...
);

CREATE VIRTUAL TABLE jobs_fts USING fts5(
    title, company, description
);
```

#### `core/scrapers/`
**Purpose**: Job board scraping (10 sources)
- **Greenhouse** - ATS scraper (HTML)
- **Lever** - ATS scraper (HTML)
- **LinkedIn** - Session cookie authentication
- **Indeed** - Query-based search
- **RemoteOK** - JSON API
- **Wellfound** - HTML scraper (formerly AngelList)
- **WeWorkRemotely** - RSS feed parsing
- **BuiltIn** - City-specific tech jobs (HTML)
- **HN Who's Hiring** - Algolia API for monthly threads
- **JobsWithGPT** - API client

**Architecture:**
```rust
#[async_trait]
pub trait JobScraper: Send + Sync {
    async fn scrape(&self) -> ScraperResult;
    fn name(&self) -> &'static str;
}
```

**Hash Computation:**
```rust
SHA-256(company + title + location + url)
```

**Rate Limiting:**
- 2 second delay between companies
- 30 second timeout per request

#### `core/scoring/`
**Purpose**: Multi-factor job scoring
- Weighted scoring algorithm
- Configurable factors

**Algorithm:**
```rust
total_score = (
    skills_match   * 0.40 +
    salary_match   * 0.25 +
    location_match * 0.20 +
    company_match  * 0.05 +
    recency_boost  * 0.10
)
```

#### `core/notify/`
**Purpose**: Alert notifications
- Slack webhook integration (v1.0)
- Email (v2.0)

**Security:**
- Webhook URL validation
- HTTPS enforcement
- Domain allowlisting

#### `core/scheduler/`
**Purpose**: Automated job scraping
- Configurable interval (1-168 hours)
- Graceful shutdown
- Error recovery

**Workflow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Schedule    â”‚
â”‚  (every 2h)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrape All   â”‚â”€â”€> 10 sources in parallel:
â”‚   Sources    â”‚    Greenhouse, Lever, LinkedIn, Indeed,
â”‚              â”‚    RemoteOK, Wellfound, WeWorkRemotely,
â”‚              â”‚    BuiltIn, HN Hiring, JobsGPT
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Score Jobs  â”‚â”€â”€> Multi-factor scoring
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Store in DB â”‚â”€â”€> SQLite (upsert)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send Alerts  â”‚â”€â”€> Slack/Discord/Teams/Email (if score >= threshold)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Commands (`src/commands/`)

Tauri command handlers (RPC interface between React and Rust).

**All Commands:**
```rust
search_jobs()              // Trigger manual scrape
get_recent_jobs(limit)     // Get N recent jobs
get_job_by_id(id)          // Get specific job
get_config()               // Get user config
save_config(config)        // Save user config
validate_slack_webhook()   // Test webhook
get_statistics()           // Get aggregate stats
get_scraping_status()      // Get scheduler status
is_first_run()             // Check first-time setup
complete_setup(config)     // Complete onboarding
search_jobs_query(q)       // Full-text search
```

**Error Handling:**
- All commands return `Result<T, String>`
- Errors logged with `tracing`
- User-friendly error messages

### 3. Platforms (`src/platforms/`)

OS-specific code (conditionally compiled).

**Windows:**
```rust
get_data_dir()    // %LOCALAPPDATA%\JobSentinel
get_config_dir()  // %APPDATA%\JobSentinel
```

**macOS:**
```rust
get_data_dir()    // ~/Library/Application Support/JobSentinel
get_config_dir()  // ~/.config/jobsentinel
get_cache_dir()   // ~/Library/Caches/JobSentinel
get_logs_dir()    // ~/Library/Logs/JobSentinel
```

**Linux:**
```rust
get_data_dir()    // ~/.local/share/jobsentinel
get_config_dir()  // ~/.config/jobsentinel
```

---

## Data Flow

### Complete Scraping Cycle

```
1. User triggers scrape OR scheduler fires
   â”‚
   v
2. Scheduler::run_scraping_cycle()
   â”‚
   â”œâ”€â”€> Scrape Greenhouse companies (parallel)
   â”œâ”€â”€> Scrape Lever companies (parallel)
   â””â”€â”€> Scrape JobsWithGPT (parallel)
   â”‚
   v
3. Parse HTML/JSON â†’ Vec<Job>
   â”‚
   v
4. For each job:
   â”œâ”€â”€> Compute SHA-256 hash
   â”œâ”€â”€> Score job (multi-factor)
   â””â”€â”€> Store in database (upsert)
   â”‚
   v
5. Get high-scoring jobs (score >= threshold)
   â”‚
   v
6. For each high-scoring job:
   â””â”€â”€> Send Slack notification (if not already sent)
   â”‚
   v
7. Return results to UI
```

### Configuration Flow

```
User edits config in UI
   â”‚
   v
Frontend calls save_config(config)
   â”‚
   v
Rust validates config
   â”‚
   â”œâ”€â”€> Valid: Save to ~/.config/jobsentinel/config.json
   â””â”€â”€> Invalid: Return error with details
```

---

## Technology Stack

### Backend (Rust)

| Category | Technology | Purpose |
|----------|------------|---------|
| **Framework** | Tauri 2.x | Desktop app framework |
| **Async Runtime** | Tokio | Async I/O and scheduling |
| **Database** | SQLite (sqlx) | Local data storage |
| **HTTP Client** | reqwest | Web scraping |
| **HTML Parser** | scraper | Parse job boards |
| **Serialization** | serde + serde_json | Config and data serialization |
| **Error Handling** | thiserror + anyhow | Structured error handling |
| **Logging** | tracing | Structured logging |
| **Hashing** | sha2 | Job deduplication |

### Frontend (React)

| Category | Technology | Purpose |
|----------|------------|---------|
| **Framework** | React 19 | UI framework |
| **Language** | TypeScript | Type-safe JavaScript |
| **Build Tool** | Vite | Fast dev server and build |
| **Styling** | Tailwind CSS | Utility-first CSS |

---

## Design Principles

### 1. **Separation of Concerns**

- **Core**: Platform-agnostic business logic
- **Commands**: Thin RPC layer (no business logic)
- **Platforms**: OS-specific code only

### 2. **Dependency Inversion**

```rust
// Good âœ…: Core depends on abstractions
#[async_trait]
pub trait JobScraper: Send + Sync {
    async fn scrape(&self) -> ScraperResult;
}

// Bad âŒ: Core depends on concrete types
pub struct GreenhouseScraper { ... }
```

### 3. **Error Handling**

- Use `thiserror` for library errors (specific, structured)
- Use `anyhow` for application errors (context)
- Never use `.unwrap()` in production code
- Always provide context with errors

### 4. **Async-First**

- Use `async/await` for I/O operations
- Avoid blocking the async runtime
- Use `tokio::spawn` for CPU-intensive work

### 5. **Security by Default**

- Input validation at boundaries
- No hardcoded secrets
- HTTPS only for webhooks
- Domain allowlisting

---

## Security Architecture

### Threat Model

| Threat | Mitigation |
|--------|------------|
| **Data exfiltration** | Webhook URL validation (only slack.com) |
| **SQL injection** | Parameterized queries (sqlx) |
| **XSS** | No eval(), sanitized HTML parsing |
| **Secrets in code** | No hardcoded secrets, user-provided webhooks |
| **Untrusted input** | Strict validation (lengths, formats, ranges) |

### Security Layers

1. **Input Validation**
   - Config validation (strict limits)
   - URL validation (format + domain allowlisting)
   - String length limits

2. **Database Security**
   - Parameterized queries (no string concatenation)
   - Transaction isolation
   - Field length validation

3. **Network Security**
   - HTTPS only
   - 30 second timeouts
   - User-Agent headers
   - Domain allowlisting for webhooks

4. **Data Privacy**
   - All data stored locally
   - No telemetry
   - No cloud dependencies (v1.0)

---

## Future Architecture (v2.0)

### Cloud Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Desktop    â”‚ â”€â”€â”
â”‚     App      â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                   â”œâ”€â”€> Load Balancer
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   Web App    â”‚ â”€â”€â”˜
â”‚   (React)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cloud Backend (GCP/AWS)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Compute (Cloud Run)   â”‚  â”‚
â”‚  â”‚  - Job scrapers        â”‚  â”‚
â”‚  â”‚  - Scoring engine      â”‚  â”‚
â”‚  â”‚  - Notifications       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Storage               â”‚  â”‚
â”‚  â”‚  - PostgreSQL (jobs)   â”‚  â”‚
â”‚  â”‚  - Redis (cache)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Tenant Architecture

- Shared scraper pool (cost optimization)
- Per-user scoring and notifications
- User authentication (OAuth)
- Encrypted user data

---

## Performance Characteristics

| Operation | Latency | Notes |
|-----------|---------|-------|
| Config load | <1ms | File read + JSON parse |
| Job upsert | <5ms | SQLite with indexes |
| Job search | <10ms | FTS5 indexed search |
| Scrape single company | 1-5s | Network dependent |
| Score single job | <1ms | Pure computation |
| Full scraping cycle | 30-120s | Depends on # of companies |

---

**Last Updated**: January 17, 2026
**Version**: 1.3
**Maintained By**: The Rust Mac Overlord ğŸ¦€

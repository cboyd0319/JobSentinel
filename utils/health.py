"""
Health monitoring and system status reporting for the job scraper.
"""

import os
import platform
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import psutil

from notify import slack
from src.database import get_database_stats
from utils.config import config_manager
from utils.logging import get_logger

logger = get_logger("health")


@dataclass
class HealthMetric:
    """A single health metric measurement."""

    name: str
    value: float
    unit: str
    status: str  # "ok", "warning", "critical"
    threshold_warning: Optional[float] = None
    threshold_critical: Optional[float] = None
    message: Optional[str] = None


class HealthMonitor:
    """Monitors system health and performance metrics."""

    def __init__(self):
        self.start_time = time.time()
        self.last_check = None

    def check_system_resources(self) -> List[HealthMetric]:
        """Check system resources (CPU, memory, disk)."""
        metrics = []

        # CPU usage
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_status = "ok"
        if cpu_percent > 80:
            cpu_status = "critical"
        elif cpu_percent > 60:
            cpu_status = "warning"

        metrics.append(
            HealthMetric(
                name="cpu_usage",
                value=cpu_percent,
                unit="%",
                status=cpu_status,
                threshold_warning=60,
                threshold_critical=80,
                message=f"CPU usage: {cpu_percent:.1f}%",
            )
        )

        # Memory usage
        memory = psutil.virtual_memory()
        mem_percent = memory.percent
        mem_status = "ok"
        if mem_percent > 90:
            mem_status = "critical"
        elif mem_percent > 75:
            mem_status = "warning"

        metrics.append(
            HealthMetric(
                name="memory_usage",
                value=mem_percent,
                unit="%",
                status=mem_status,
                threshold_warning=75,
                threshold_critical=90,
                message=f"Memory usage: {mem_percent:.1f}% "
                f"({memory.used / 1024**3:.1f}GB / {memory.total / 1024**3:.1f}GB)",
            )
        )

        # Disk usage (where the scraper is installed)
        disk = psutil.disk_usage(".")
        disk_percent = (disk.used / disk.total) * 100
        disk_status = "ok"
        if disk_percent > 95:
            disk_status = "critical"
        elif disk_percent > 85:
            disk_status = "warning"

        metrics.append(
            HealthMetric(
                name="disk_usage",
                value=disk_percent,
                unit="%",
                status=disk_status,
                threshold_warning=85,
                threshold_critical=95,
                message=f"Disk usage: {disk_percent:.1f}% ({disk.used / 1024**3:.1f}GB / {disk.total / 1024**3:.1f}GB)",
            )
        )

        return metrics

    async def check_database_health_async(self) -> List[HealthMetric]:
        """Check database health and statistics (async version)."""
        metrics = []

        try:
            stats = await get_database_stats()

            # Total jobs
            total_jobs = stats.get("total_jobs", 0)
            metrics.append(
                HealthMetric(
                    name="total_jobs",
                    value=total_jobs,
                    unit="jobs",
                    status="ok",
                    message=f"Total jobs in database: {total_jobs}",
                )
            )

            # Recent jobs (last 24h)
            recent_jobs = stats.get("recent_jobs_24h", 0)
            recent_status = "ok"
            if recent_jobs == 0:
                recent_status = "warning"
                message = "No new jobs found in last 24 hours"
            else:
                message = f"New jobs in last 24h: {recent_jobs}"

            metrics.append(
                HealthMetric(
                    name="recent_jobs_24h",
                    value=recent_jobs,
                    unit="jobs",
                    status=recent_status,
                    message=message,
                )
            )

            # High score jobs
            high_score_jobs = stats.get("high_score_jobs", 0)
            metrics.append(
                HealthMetric(
                    name="high_score_jobs",
                    value=high_score_jobs,
                    unit="jobs",
                    status="ok",
                    message=f"High-scoring jobs (â‰¥0.8): {high_score_jobs}",
                )
            )

        except Exception as e:
            logger.error(f"Failed to get database stats: {e}")
            metrics.append(
                HealthMetric(
                    name="database_status",
                    value=0,
                    unit="status",
                    status="critical",
                    message=f"Database error: {e}",
                )
            )

        return metrics

    def check_log_files(self) -> List[HealthMetric]:
        """Check log file sizes and recent activity."""
        metrics = []

        log_dir = "data/logs"
        if not os.path.exists(log_dir):
            metrics.append(
                HealthMetric(
                    name="log_directory",
                    value=0,
                    unit="status",
                    status="warning",
                    message="Log directory does not exist",
                )
            )
            return metrics

        try:
            # Check log file sizes
            total_log_size = 0
            recent_log_activity = False
            now = datetime.now()

            for log_file in os.listdir(log_dir):
                if log_file.endswith(".log"):
                    log_path = os.path.join(log_dir, log_file)
                    if os.path.isfile(log_path):
                        file_size = os.path.getsize(log_path)
                        total_log_size += file_size

                        # Check if file was modified in last hour
                        mod_time = datetime.fromtimestamp(os.path.getmtime(log_path))
                        if now - mod_time < timedelta(hours=1):
                            recent_log_activity = True

            # Log size metric
            log_size_mb = total_log_size / (1024 * 1024)
            log_size_status = "ok"
            if log_size_mb > 500:
                log_size_status = "critical"
            elif log_size_mb > 100:
                log_size_status = "warning"

            metrics.append(
                HealthMetric(
                    name="log_size",
                    value=log_size_mb,
                    unit="MB",
                    status=log_size_status,
                    threshold_warning=100,
                    threshold_critical=500,
                    message=f"Total log size: {log_size_mb:.1f}MB",
                )
            )

            # Recent activity metric
            activity_status = "ok" if recent_log_activity else "warning"
            metrics.append(
                HealthMetric(
                    name="log_activity",
                    value=1 if recent_log_activity else 0,
                    unit="status",
                    status=activity_status,
                    message=(
                        "Recent log activity detected"
                        if recent_log_activity
                        else "No recent log activity"
                    ),
                )
            )

        except Exception as e:
            logger.error(f"Failed to check log files: {e}")
            metrics.append(
                HealthMetric(
                    name="log_check",
                    value=0,
                    unit="status",
                    status="critical",
                    message=f"Log check error: {e}",
                )
            )

        return metrics

    def check_configuration(self) -> List[HealthMetric]:
        """Check configuration validity and notification setup."""
        metrics = []

        try:
            # Test configuration loading
            config_manager.load_config()
            metrics.append(
                HealthMetric(
                    name="configuration",
                    value=1,
                    unit="status",
                    status="ok",
                    message="Configuration loaded successfully",
                )
            )

            # Check notification setup
            notification_config = config_manager.get_notification_config()

            slack_status = "ok" if notification_config.validate_slack() else "warning"
            metrics.append(
                HealthMetric(
                    name="slack_config",
                    value=1 if notification_config.validate_slack() else 0,
                    unit="status",
                    status=slack_status,
                    message=(
                        "Slack configured"
                        if notification_config.validate_slack()
                        else "Slack not configured"
                    ),
                )
            )

            # Email notifications removed - skipping email config check
            # email_status = "ok" if notification_config.validate_email() else "warning"
            # metrics.append(
            #     HealthMetric(
            #         name="email_config",
            #         value=1 if notification_config.validate_email() else 0,
            #         unit="status",
            #         status=email_status,
            #         message=("Email configured" if notification_config.validate_email() else "Email not configured"),
            #     )
            # )

        except Exception as e:
            logger.error(f"Configuration check failed: {e}")
            metrics.append(
                HealthMetric(
                    name="configuration",
                    value=0,
                    unit="status",
                    status="critical",
                    message=f"Configuration error: {e}",
                )
            )

        return metrics

    async def generate_health_report_async(self) -> Dict:
        """Generate comprehensive health report (async version)."""
        logger.info("Generating health report...")

        all_metrics = []
        all_metrics.extend(self.check_system_resources())
        all_metrics.extend(await self.check_database_health_async())
        all_metrics.extend(self.check_log_files())
        all_metrics.extend(self.check_configuration())

        # Calculate overall status
        critical_count = len([m for m in all_metrics if m.status == "critical"])
        warning_count = len([m for m in all_metrics if m.status == "warning"])

        if critical_count > 0:
            overall_status = "critical"
        elif warning_count > 0:
            overall_status = "warning"
        else:
            overall_status = "ok"

        uptime = time.time() - self.start_time
        uptime_hours = uptime / 3600

        report = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": overall_status,
            "uptime_hours": uptime_hours,
            "system_info": {
                "platform": platform.platform(),
                "python_version": platform.python_version(),
                "hostname": platform.node(),
            },
            "metrics": [
                {
                    "name": m.name,
                    "value": m.value,
                    "unit": m.unit,
                    "status": m.status,
                    "message": m.message,
                    "threshold_warning": m.threshold_warning,
                    "threshold_critical": m.threshold_critical,
                }
                for m in all_metrics
            ],
            "summary": {
                "total_metrics": len(all_metrics),
                "ok_count": len([m for m in all_metrics if m.status == "ok"]),
                "warning_count": warning_count,
                "critical_count": critical_count,
            },
        }

        self.last_check = datetime.now()
        logger.info(
            f"Health report generated: {overall_status} status with {warning_count} warnings, "
            f"{critical_count} critical issues"
        )

        return report

    def generate_health_report(self) -> Dict:
        """Generate comprehensive health report (sync wrapper)."""
        import asyncio

        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # In async context, use async version
                logger.warning("Sync health report called in async context - using limited checks")
                all_metrics = []
                all_metrics.extend(self.check_system_resources())
                all_metrics.extend(self.check_log_files())
                all_metrics.extend(self.check_configuration())
            else:
                # Not in async context, safe to run async version
                return asyncio.run(self.generate_health_report_async())
        except RuntimeError:
            # No event loop, create one
            return asyncio.run(self.generate_health_report_async())

        # Fallback for sync-only context
        logger.info("Generating health report...")

        all_metrics = []
        all_metrics.extend(self.check_system_resources())
        all_metrics.extend(self.check_log_files())
        all_metrics.extend(self.check_configuration())

        # Calculate overall status
        critical_count = len([m for m in all_metrics if m.status == "critical"])
        warning_count = len([m for m in all_metrics if m.status == "warning"])

        if critical_count > 0:
            overall_status = "critical"
        elif warning_count > 0:
            overall_status = "warning"
        else:
            overall_status = "ok"

        uptime = time.time() - self.start_time
        uptime_hours = uptime / 3600

        report = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": overall_status,
            "uptime_hours": uptime_hours,
            "system_info": {
                "platform": platform.platform(),
                "python_version": platform.python_version(),
                "hostname": platform.node(),
            },
            "metrics": [
                {
                    "name": m.name,
                    "value": m.value,
                    "unit": m.unit,
                    "status": m.status,
                    "message": m.message,
                    "threshold_warning": m.threshold_warning,
                    "threshold_critical": m.threshold_critical,
                }
                for m in all_metrics
            ],
            "summary": {
                "total_metrics": len(all_metrics),
                "ok_count": len([m for m in all_metrics if m.status == "ok"]),
                "warning_count": warning_count,
                "critical_count": critical_count,
            },
        }

        self.last_check = datetime.now()
        logger.info(
            f"Health report generated: {overall_status} status with {warning_count} warnings, "
            f"{critical_count} critical issues"
        )

        return report

    def send_health_alert(self, report: Dict):
        """Send health alert if there are critical issues."""
        if report["overall_status"] == "critical":
            try:
                notification_config = config_manager.get_notification_config()

                if notification_config.validate_slack():
                    critical_metrics = [m for m in report["metrics"] if m["status"] == "critical"]

                    alert_message = {
                        "blocks": [
                            {
                                "type": "header",
                                "text": {
                                    "type": "plain_text",
                                    "text": "ðŸš¨ Job Scraper Health Alert",
                                },
                            },
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"*Critical issues detected on {report['system_info']['hostname']}*\n\n"
                                    f"*Issues:*\n"
                                    + "\n".join([f"â€¢ {m['message']}" for m in critical_metrics]),
                                },
                            },
                            {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"*System uptime:* {report['uptime_hours']:.1f} hours\n"
                                    f"*Timestamp:* {report['timestamp']}",
                                },
                            },
                        ]
                    }

                    slack.send_slack_alert([], custom_message=alert_message)
                    logger.info("Health alert sent to Slack")

            except Exception as e:
                logger.error(f"Failed to send health alert: {e}")


# Global health monitor instance
health_monitor = HealthMonitor()
